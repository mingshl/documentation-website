---
layout: default
title: Template Query
parent: Specialized queries
nav_order: 55
---

# Template query

Use a `template` query to holder inner query containing placeholders with "${}" syntax. These placeholders are resolved after the search request has been processed by search request processors. This feature is particularly useful when the initial search request contains placeholders or incomplete data that will be resolved by a search request processor (e.g., [ml_inference search request processor]({{site.url}}{{site.baseurl}}/search-plugins/search-pipelines/ml-inference-search-request/)).

## Example

The following example shows a template query with a placeholder for a k-NN query. The placeholder `"${text_embedding}"` will be replaced by the ml_inference search request processor:

```json
GET /template-knn-index/_search?search_pipeline=my_knn_pipeline
{
  "query": {
    "template": {
      "knn": {
        "text_embedding": {
          "vector": "${text_embedding}", // Placeholder for the vector field
          "k": 2
        }
      }
    }
  },
  "ext": {
    "ml_inference": {
      "text": "sneakers" // Input text for the ml_inference processor
    }
  }
}
```
To use the template query with a search request processor, you need to configure a search pipeline. The following is an example configuration for an ml_inference search request processor:

```json
PUT /_search/pipeline/my_knn_pipeline
{
  "request_processors": [
    {
      "ml_inference": {
        "model_id": "Sz-wFZQBUpPSu0bsJTBG",
        "input_map": [
          {
            "inputText": "ext.ml_inference.text" // Map input text from the request
          }
        ],
        "output_map": [
          {
            "text_embedding": "embedding" // Map output to the placeholder
          }
        ]
      }
    }
  ]
}

```

Rewritten Search Request
After the ml_inference search request processor runs, the search request is rewritten as follows:
```json
GET /template-knn-1/_search
{
  "query": {
    "template": {
      "knn": {
        "text_embedding": {
          "vector": [0.6328125, 0.26953125, ...], // Vector generated by ml_inference
          "k": 2
        }
      }
    }
  },
  "ext": {
    "ml_inference": {
      "text": "sneakers",
      "text_embedding": [0.6328125, 0.26953125, ...] // Output from ml_inference
    }
  }
}
```

{% include copy-curl.html %}

#### Use case: semantic search with ml_inference search request processor 
The following is a complete example of using the template query with an [ml_inference search request processor]({{site.url}}{{site.baseurl}}/search-plugins/search-pipelines/ml-inference-search-request/) for semantic search:

1. Check predict using a text embedding model: 
   The pre-requisite of using ml_inference search request processor is to have a model hosted or connected to remote service. For more information about local models, see [Using ML models within OpenSearch]({{site.url}}{{site.baseurl}}/ml-commons-plugin/using-ml-models/).
   For more information about externally hosted models, see [Connecting to externally hosted models]({{site.url}}{{site.baseurl}}/ml-commons-plugin/remote-models/index/).
   This is a sample text embedding model.  
    ```json
    POST /_plugins/_ml/models/Sz-wFZQBUpPSu0bsJTBG/_predict
    {
      "parameters": {
        "inputText": "happy moments"
      }
    }

    ```
   Example response:: 
    ```json
    {
      "inference_results": [
        {
          "output": [
            {
              "name": "response",
              "dataAsMap": {
                "embedding": [
                  0.6328125,
                  0.26953125,
                  0.41796875,
                  -0.00579833984375,
                  1.859375,
                  0.2734375,
                  0.130859375,
                  -0.001007080078125,
                  0.138671875,
                  ...],
                "inputTextTokenCount": 2
              }
            }
          ],
          "status_code": 200
        }
      ]
    }
    
    ```
   {% include copy-curl.html %}
 
2. Create an Ingest Pipeline:
    ```json
    PUT /_ingest/pipeline/knn_pipeline
    {
      "description": "knn_pipeline",
      "processors": [
        {
          "ml_inference": {
            "model_id": "Sz-wFZQBUpPSu0bsJTBG",
            "input_map": [
              {
                "inputText": "text"
              }
            ],
            "output_map": [
              {
                "text_embedding": "embedding"
              }
            ]
          }
        }
      ]
    }
    ```
   {% include copy-curl.html %}

   Example response::
    ```json
    {
      "acknowledged": true
    }
    ```
3. Index a Document::
    ```json
    
    PUT /template-knn-1/_doc/1
    {
      "text": "red shoes"
    }
    
    GET /template-knn-1/_doc/1
    ```
   {% include copy-curl.html %}

    Example response::
    ```json
    {
      "_index": "template-knn-1",
      "_id": "1",
      "_version": 2,
      "_seq_no": 1,
      "_primary_term": 1,
      "found": true,
      "_source": {
        "text_embedding": [
          -0.69140625,
          0.8125,
          0.51953125,
          -0.7421875,
          0.6875,
          0.4765625,
          -0.34375,
          ...],
        "text": "red shoes"
      }
    }
    ```

   4. Search with the Template Query:
       ```json
       GET /template-knn-1/_search?search_pipeline=my_knn_pipeline
       {
         "query": {
           "template": {
             "knn": {
               "text_embedding": {
                 "vector": "${text_embedding}",
                 "k": 2
               }
             }
           }
         },
         "ext": {
           "ml_inference": {
             "text": "sneakers"
           }
         }
       }
    
       ```
      {% include copy-curl.html %}
   
   Example response::
      ```json
       {
         "took": 611,
         "timed_out": false,
         "_shards": {
           "total": 5,
           "successful": 5,
           "skipped": 0,
           "failed": 0
         },
         "hits": {
           "total": {
             "value": 1,
             "relation": "eq"
           },
           "max_score": 0.0019327316,
           "hits": [
             {
               "_index": "template-knn-1",
               "_id": "1",
               "_score": 0.0019327316,
               "_source": {
                 "text_embedding": [
                   -0.69140625,
                   0.8125,
                   0.51953125,
                   ..],
                 "text": "red shoes"
               }
             }
           ]
         }
       }
       ```

## Limitations
The template query cannot be executed without a search request processor that produce variables to pipelineContext.

